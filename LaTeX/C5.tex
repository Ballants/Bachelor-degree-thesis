\chapter{Mitigation di Adversarial Attacks: esperimenti}
\label{chap:5}
Durante il lavoro di tesi sono state testate due delle tecniche di mitigation di adversarial attacks illustrate nella sezione \ref{C3: Mitigation}:
    \begin{itemize}
        \item Adversarial Training (\ref{BF Adversarial Training}): testato su un solo modello (DenseNet121), un solo attacco (FGSM) ed entrambi i datasets. 
        \item Pix2Pix GAN (\ref{Pix2Pix GAN}): testato su tutti i modelli, tutti gli attacchi ed entrambi i datasets.
    \end{itemize}
    
    Le scelte adottate sono dovute alla valutazione di tempi e costi computazionali richiesti per l'applicazione dei metodi. L'Adversarial Training, a differenza della GAN, richiede un raddoppio della dimensione del Training dataset e, di conseguenza, un significativo aumento di tempo e risorse investite nella fase di training del modello.
    
    Inoltre, durante l'esecuzione degli esperimenti è emerso che l'utilizzo dell'Adversarial Training comportava un drop dell'accuracy del modello sulle immagini pulite del Testing dataset.

\newpage
\section{Adversarial Training}
    Di seguito si riportano i risultati degli esperimenti effettuati.
    Si confrontano le due tecniche di training prese in esame: Hold-out Training (\ref{Hold-Out method}) e Adversarial Training. 
    Si mostra la variazione dell'accuracy del modello DenseNet121 sulle immagini pulite (No Attacco) e perturbate di entrambi i datasets:
    \begin{table}[!h]
        \centering
        \begin{tabular}{|c||c|c|}
            \hline
            \multicolumn{3}{|c|}{\textbf{Chest X-Ray Dataset}} \rule[-3mm]{0mm}{8mm}\\
            \hline
            \rule[-3mm]{0mm}{8mm}
            & \textbf{No Attacco} & \textbf{FGSM}\\
            \hline \hline
            \rule[-3mm]{0mm}{8mm}
            \textbf{Hold-Out Training}      & 0.9845 & 0.5076 \\
             & & (-48.44\%) \\
            \hline
            \rule[-3mm]{0mm}{8mm}
            \textbf{Adversarial Training}   & 0.9020 & 0.8003 \\
             & &  (-11.27\%)\\
            \hline
        \end{tabular}
        \caption{\textit{Adversarial Training} del modello \textit{DenseNet121} sul dataset \textit{Chest X-Ray}}
        \label{Adversarial Training Chest X-Ray}
    \end{table}
    
    \begin{table}[!h]
        \centering
        \begin{tabular}{|c||c|c|}
            \hline
            \multicolumn{3}{|c|}{\textbf{Brain Tumor MRI Dataset}} \rule[-3mm]{0mm}{8mm}\\
            \hline
            \rule[-3mm]{0mm}{8mm}
            & \textbf{No Attacco} & \textbf{FGSM}\\
            \hline \hline
            \rule[-3mm]{0mm}{8mm}
            \textbf{Hold-Out Training}      & 0.9554 & 0.3137 \\
             & & (-67.17\%) \\
            \hline
            \rule[-3mm]{0mm}{8mm}
            \textbf{Adversarial Training }  & 0.8876 & 0.7697 \\
             & & (-13.28\%) \\
            \hline
        \end{tabular}
        \caption{\textit{Adversarial Training} del modello \textit{DenseNet121} sul dataset \textit{Brain Tumor MRI}}
        \label{Adversarial Training Brain Tumor MRI}
    \end{table}
    
I risultati dimostrano che, sebbene i modelli siano estremamente sensibili agli adversarial attacks, l'adversarial training mostra la premessa per lo sviluppo di una difesa efficace contro gli attacchi. La vulnerabilità delle singole immagini può essere usata per aumentare le prestazioni del modello identificando le immagini più a rischio di errore di classificazione.

Tuttavia, il metodo rimane di difficile applicazione a causa degli elevati tempi e costi computazionali richiesti.

Inoltre, nonostante il modello risulti più robusto durante la fase di testing su immagini perturbate, l'accuracy generale su immagini pulite subisce un calo consistente, di circa il $10\%$.

\newpage
\section{Architettura della Pix2Pix GAN}
L'architettura della GAN utilizzata durante il lavoro di tesi è tratta da %[bibl: https://arxiv.org/pdf/1611.07004.pdf] 
\cite{isola2016image}:
    %\paragraph{Architettura del Generator}
        \begin{table}[!h]
            \centering
            \begin{tabular}{|c|c||c|c|}
                \hline
                \multicolumn{4}{|c|}{\textbf{Generator}} \rule[-3mm]{0mm}{8mm}\\
                \hline \hline
                \multicolumn{2}{|c||}{\textbf{Encoder}} & 
                \multicolumn{2}{|c|}{\textbf{U-Net Decoder}} \rule[-3mm]{0mm}{8mm}\\
                \hline \hline
                \rule[-3mm]{0mm}{8mm}
                \textbf{Layers} & \textbf{Output size} & \textbf{Layers} & \textbf{Output size}\\
                \hline
                \rule[-3mm]{0mm}{8mm}
                C64 & $128 \times 128$      & CD512 & $2 \times 2$ \\
                lReLU(0.2)      &                & BN + ReLU + Dropout(0.5) & \\
                \hline
                \rule[-3mm]{0mm}{8mm}
                C128 & $64 \times 64$       & CD1024 & $4 \times 4$ \\
                BN + lReLU(0.2) &                & BN + ReLU + Dropout(0.5) & \\
                \hline
                \rule[-3mm]{0mm}{8mm}
                C256 & $32 \times 32$       & CD1024 & $8 \times 8$ \\
                BN + lReLU(0.2) &                & BN + ReLU + Dropout(0.5) & \\
                \hline
                \rule[-3mm]{0mm}{8mm}
                C512 & $16 \times 16$       & CD1024 & $16 \times 16$ \\
                BN + lReLU(0.2) &                & BN + ReLU + Dropout(0.5) & \\
                \hline
                \rule[-3mm]{0mm}{8mm}
                C512 & $8 \times 8$         & CD1024 & $32 \times 32$ \\
                BN + lReLU(0.2) &                & BN + ReLU + Dropout(0.5) & \\
                \hline
                \rule[-3mm]{0mm}{8mm}
                C512 & $4 \times 4$         & CD512 & $64 \times 64$ \\
                BN + lReLU(0.2) &                & BN + ReLU + Dropout(0.5) & \\
                \hline
                \rule[-3mm]{0mm}{8mm}
                C512 & $2 \times 2$         & CD256 & $128 \times 128$ \\
                BN + lReLU(0.2) &                & BN + ReLU + Dropout(0.5) & \\
                \hline
                \rule[-3mm]{0mm}{8mm}
                C512 & $1 \times 1$         & CD128 & $256 \times 256$ \\
                lReLU(0.2)      &                & BN + ReLU + Dropout(0.5) & \\
                \hline
            \end{tabular}
            \caption{Architettura del Generator. 
            C$k$: Convolutional layer con $k$ $4 \times 4$ filtri e $stride=2$. BN: BatchNorm. 
            CD$k$: ConvTranspose2d layer con $k$ $4 \times 4$ filtri e $stride=2$. \\
            Activation function del Generator: $Tanh$}
            \label{Generator Architecture}
        \end{table}

\newpage
        \begin{table}[!h]
            \centering
            \begin{tabular}{|c|c|}
                \hline
                \multicolumn{2}{|c|}{\textbf{Discriminator $70 \times 70$}} \rule[-3mm]{0mm}{8mm}\\
                \hline \hline
                \rule[-3mm]{0mm}{8mm}
                \textbf{Layers} & \textbf{Output size} \\
                \hline \hline
                \rule[-3mm]{0mm}{8mm}
                C64                 & $128 \times 128$  \\
                lReLU(0.2) & \\
                \hline
                \rule[-3mm]{0mm}{8mm}
                C128                & $64 \times 64$  \\
                BN + lReLU(0.2) & \\
                \hline
                \rule[-3mm]{0mm}{8mm}
                C256                & $32 \times 32$  \\
                BN + lReLU(0.2) & \\
                \hline
                \rule[-3mm]{0mm}{8mm}
                C512                & $31 \times 31$  \\
                BN + lReLU(0.2) & \\
                \hline
                \rule[-3mm]{0mm}{8mm}
                C1                & $30 \times 30$  \\
                lReLU(0.2) & \\
                \hline
            \end{tabular}
            \caption{Architettura del Discriminator. 
            C$k$: Convolutional layer con $k$ $4 \times 4$ filtri e $stride=2$. BN: BatchNorm. \\
            Activation function del Discriminator: $Sigmoid$}
            \label{Discriminator architecture}
        \end{table}
    
    \subsection{Risultati}
    
        \begin{table}[!h]
                \centering
                \begin{tabular}{|c||c|c|c|c|c|}
                    \hline
                    \multicolumn{6}{|c|}{\textbf{Chest X-Ray Dataset}} \rule[-3mm]{0mm}{8mm}\\
                    \hline \hline
                    \rule[-3mm]{0mm}{8mm}
                    \textbf{Model} & \textbf{No Attacco} & \textbf{FGSM} & \textbf{BIM} & \textbf{PGD} & \textbf{DeepFool} \\
                    \hline \hline
                    \rule[-3mm]{0mm}{8mm}
                    DenseNet121 & 0.9845 & 0.8794 & 0.8167 & 0.7903 & 0.8423\\
                        &  & (-10.68\%) & (-17.04\%) & (-19.73\%) & (-14.44\%)\\
                    \hline
                    \rule[-3mm]{0mm}{8mm}
                    ResNet152   & 0.9811 & 0.8154 & 0.7997 & 0.7776  & 0.7901\\
                        &  & (-16.89\%) & (-18.49\%) & (-20.74\%) & (-19.47\%)\\
                    \hline
                    \rule[-3mm]{0mm}{8mm}
                    VGG19       & 0.9482 & 0.6287 & 0.5893 & 0.5608 & 0.6339\\
                        &  & (-33.70\%) & (-37.85\%) & (-40.86\%) & (-33.15\%)\\
                    \hline
                    \rule[-3mm]{0mm}{8mm}
                    MobileNetV2 & 0.9744 & 0.7963 & 0.7348 & 0.7096 & 0.8055\\
                        &  & (-18.28\%) & (-24.59\%) & (-27.18\%) & (-17.33\%)\\
                    \hline
                    \rule[-3mm]{0mm}{8mm}
                    InceptionV3 & 0.9668 & 0.8094 & 0.7728 & 0.7418 & 0.7904\\
                        &  & (-16.28\%) & (-20.07\%) & (-23.27\%) & (-18.25\%)\\
                    \hline
                \end{tabular}
                \caption{Risultati dell'utilizzo della GAN per mitigare gli attacchi applicati al dataset \textit{Chest X-Ray}.
                Ogni cella riporta l'accuracy del modello (riga) sulle immagini perturbate dall'attacco (colonna) e il relativo drop in percentuale rispetto all'accuracy originale.}
                \label{Mitigation Results Chest X-Ray}
            \end{table}
            
            \newpage
            \begin{table}[!h]
                \centering
                \begin{tabular}{|c||c|c|c|c|c|}
                    \hline
                    \multicolumn{6}{|c|}{\textbf{Brain Tumor MRI Dataset}} \rule[-3mm]{0mm}{8mm}\\
                    \hline \hline
                    \rule[-3mm]{0mm}{8mm}
                    \textbf{Model} & \textbf{No Attacco} & \textbf{FGSM} & \textbf{BIM} & \textbf{PGD} & \textbf{DeepFool} \\
                    \hline \hline
                    \rule[-3mm]{0mm}{8mm}
                    DenseNet121 & 0.9554 & 0.8689 & 0.8298 & 0.8046 & 0.8577 \\
                     & & (-9.05\%) & (-13.15\%) & (-15.78\%) & (-10.23\%)\\
                    \hline
                    \rule[-3mm]{0mm}{8mm}
                    ResNet152   & 0.9332 & 0.8220 & 0.7845 & 0.7565 & 0.8126 \\
                     & & (-11.92\%) & (-15.93\%) & (-18.93\%) & (-12.92\%)\\
                    \hline
                    \rule[-3mm]{0mm}{8mm}
                    VGG19       & 0.9197 & 0.6390 & 0.6074 & 0.5545 & 0.6134 \\
                     & & (-30.52\%) & (-33.96\%) & (-39.71\%) & (-33.30\%)\\
                    \hline
                    \rule[-3mm]{0mm}{8mm}
                    MobileNetV2 & 0.9277 & 0.8035 & 0.7532 & 0.7299 & 0.7943 \\
                     & & (-13.39\%) & (-18.81\%) & (-21.32\%) & (-14.38\%)\\
                    \hline
                    \rule[-3mm]{0mm}{8mm}
                    InceptionV3 & 0.9160 & 0.7923 & 0.7789 & 0.7302 & 0.7907 \\
                     & & (-13.50\%) & (-14.97\%) & (-20.28\%) & (-13.68\%)\\
                    \hline
                \end{tabular}
                \caption{Risultati dell'utilizzo della GAN per mitigare gli attacchi applicati al dataset \textit{Brain Tumor MRI}.
                Ogni cella riporta l'accuracy del modello (riga) sulle immagini perturbate dall'attacco (colonna) e il relativo drop in percentuale rispetto all'accuracy originale.}
                \label{Mitigation Results Brain Tumor MRI}
            \end{table}
            
            L'impiego della GAN ha sicuramente portato dei miglioramenti nell'accuracy dei modelli, risultando un metodo di difesa valido.
            
            L'efficacia di attacchi in grado di azzerare l'accuracy dei modelli, BIM e PGD, è ridotta in modo significativo. In questi casi l'accuracy è stata riportata a valori solidi compresi tra 70-80\%.
            
            Oltre ad essere il modello più vulnerabile, VGG19 è anche il più difficile da difendere, indipendentemente dal tipo di attacco utilizzato. Al contempo, il modello che performa meglio, se difeso, è DenseNet121.
            
            Si noti che tutti i modelli hanno raggiunto livelli di performance superiori durante la classificazione effettuata sulle immagini del dataset con 4 classi. Si deduce che i datasets multiclass, anche se più vulnerabili, siano più facili da difendere rispetto a quelli binari.   
            
            In generale, l'utilizzo della GAN riesce a mitigare gli adversarial attacks in modo più efficace rispetto all'Adversarial Training. Inoltre, non venendo apportate modifiche alla fase di training del modello, durante la fase di testing, l'accuracy dei modelli sulle immagini pulite dei datasets rimane invariata. 
            
            \newpage
            Di seguito si riporta l'aumento dell’accuracy dei modelli in seguito all’utilizzo della GAN per mitigare gli attacchi:
            
            \begin{table}[!h]
                \centering
                \begin{tabular}{|c||c|c|c|c|c|}
                    \hline
                    \multicolumn{6}{|c|}{\textbf{Chest X-Ray Dataset}} \rule[-3mm]{0mm}{8mm}\\
                    \hline \hline
                    \rule[-3mm]{0mm}{8mm}
                    \textbf{Model} & \textbf{No Attacco} & \textbf{FGSM} & \textbf{BIM} & \textbf{PGD} & \textbf{DeepFool} \\
                    \hline \hline
                    \rule[-3mm]{0mm}{8mm}
                    DenseNet121 & 0.9845 & 0.5076  & 0.0000  & 0.0000 & 0.4502\\
                                       & & 0.8794 & 0.8167 & 0.7903 & 0.8423\\
                     \rule[-3mm]{0mm}{8mm}
                     & & (+0.3718) & (+0.8167) & (+0.7903) & (+0.3903)\\
                    \hline
                    \rule[-3mm]{0mm}{8mm}
                    ResNet152 & 0.9811 & 0.4899 & 0.0008 & 0.0017  & 0.4247\\
                                     & & 0.8154 & 0.7997 & 0.7776  & 0.7901\\
                     \rule[-3mm]{0mm}{8mm}
                     & & (+0.3255) & (+0.7989) & (+0.7759) & (+0.3654)\\
                    \hline
                    \rule[-3mm]{0mm}{8mm}
                    VGG19 & 0.9482 & 0.3792 & 0.0000 & 0.0017 & 0.2458\\
                                 & & 0.6287 & 0.5893 & 0.5608 & 0.6339\\
                     \rule[-3mm]{0mm}{8mm}
                     & & (+0.2495) & (+0.5893) & (+0.5591) & (+0.3881)\\
                    \hline
                    \rule[-3mm]{0mm}{8mm}
                    MobileNetV2 & 0.9744 & 0.4780 & 0.0000 & 0.0000 & 0.2534\\
                                       & & 0.7963 & 0.7348 & 0.7096 & 0.8055\\
                     \rule[-3mm]{0mm}{8mm}
                     & & (+0.3183) & (+0.7348) & (+0.7096) & (+0.5521)\\
                    \hline
                    \rule[-3mm]{0mm}{8mm}
                    InceptionV3 & 0.9668 & 0.4899 & 0.0059 & 0.0000 & 0.3446\\
                                       & & 0.8094 & 0.7728 & 0.7418 & 0.7904\\ 
                     \rule[-3mm]{0mm}{8mm}
                     & & (+0.3195) & (+0.7669) & (+0.7418) & (+0.4458)\\
                    \hline
                \end{tabular}
                \caption{Aumento dell'accuracy dei modelli in seguito all'utilizzo della GAN per mitigare gli attacchi applicati al dataset \textit{Chest X-Ray}.
                Ogni cella riporta l'accuracy del modello (riga) sulle immagini perturbate dall'attacco (colonna) senza e con l'impiego della GAN, e l'aumento dell'accuracy.}
                \label{Rise accuracy Chest X-Ray}
            \end{table}
            
            \newpage
            \begin{table}[!h]
                \centering
                \begin{tabular}{|c||c|c|c|c|c|}
                    \hline
                    \multicolumn{6}{|c|}{\textbf{Brain Tumor MRI Dataset}} \rule[-3mm]{0mm}{8mm}\\
                    \hline \hline
                    \rule[-3mm]{0mm}{8mm}
                    \textbf{Model} & \textbf{No Attacco} & \textbf{FGSM} & \textbf{BIM} & \textbf{PGD} & \textbf{DeepFool} \\
                    \hline \hline
                    \rule[-3mm]{0mm}{8mm}
                    DenseNet121 & 0.9554 & 0.3137 & 0.0007 & 0.0000 & 0.3334 \\
                                       & & 0.8689 & 0.8298 & 0.8046 & 0.8577 \\
                    \rule[-3mm]{0mm}{8mm}
                     & & (+0.5552) & (+0.8291) & (+0.8046) & (+0.5243)\\
                    \hline
                    \rule[-3mm]{0mm}{8mm}
                    ResNet152   & 0.9332 & 0.4273 & 0.0014 & 0.0000 & 0.4374 \\ 
                                       & & 0.8220 & 0.7845 & 0.7565 & 0.8126 \\
                    \rule[-3mm]{0mm}{8mm}
                     & & (+0.3947) & (+0.7831) & (+0.7565) & (+0.3752)\\
                    \hline
                    \rule[-3mm]{0mm}{8mm}
                    VGG19       & 0.9197 & 0.3650 & 0.0156 & 0.0044 & 0.3593 \\
                                       & & 0.6390 & 0.6074 & 0.5545 & 0.6134 \\
                    \rule[-3mm]{0mm}{8mm} 
                     & & (+0.2740) & (+0.5918) & (+0.5501) & (+0.2541)\\
                    \hline
                    \rule[-3mm]{0mm}{8mm}
                    MobileNetV2 & 0.9277 & 0.2789 & 0.0007 & 0.0000 & 0.1564 \\
                                       & & 0.8035 & 0.7532 & 0.7299 & 0.7943 \\ 
                    \rule[-3mm]{0mm}{8mm}
                     & & (+0.5246) & (+0.7525) & (+0.7299) & (+0.6379)\\
                    \hline
                    \rule[-3mm]{0mm}{8mm}
                    InceptionV3 & 0.9160 & 0.4598 & 0.0000 & 0.0000 & 0.3659 \\
                                       & & 0.7923 & 0.7789 & 0.7302 & 0.7907 \\
                    \rule[-3mm]{0mm}{8mm}
                     & & (+0.3325) & (+0.7789) & (+0.7302) & (+0.4249)\\
                    \hline
                \end{tabular}
                \caption{Aumento dell'accuracy dei modelli in seguito all'utilizzo della GAN per mitigare gli attacchi applicati al dataset \textit{Brain Tumor MRI}.
                Ogni cella riporta l'accuracy del modello (riga) sulle immagini perturbate dall'attacco (colonna) senza e con l'impiego della GAN, e l'aumento dell'accuracy.}
                \label{Rise accuracy Brain Tumor MRI}
            \end{table}